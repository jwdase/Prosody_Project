{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f33bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node064\n"
     ]
    }
   ],
   "source": [
    "# Set main root \n",
    "from setup import setup_project_root\n",
    "setup_project_root()\n",
    "\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61c9af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading de from: /om2/user/moshepol/prosody/data/raw_audio/de/validated.tsv\n",
      "Loading en from: /om2/user/moshepol/prosody/data/raw_audio/en/validated.tsv\n",
      "Loading es from: /om2/user/moshepol/prosody/data/raw_audio/es/validated.tsv\n",
      "Loading it from: /om2/user/moshepol/prosody/data/raw_audio/it/validated.tsv\n",
      "Unique de speakers: 17667\n",
      "Unique en speakers: 77437\n",
      "Unique es speakers: 16927\n",
      "Unique it speakers: 6688\n"
     ]
    }
   ],
   "source": [
    "from langaugedetection.data.com_voice_dir import open_files, person_to_group\n",
    "\n",
    "languages = ['de', 'en', 'es', 'it', ] # 'ja', 'nl', 'ta']\n",
    "# Specifying a list of the languages to\n",
    "\n",
    "files = {lang : open_files(lang, 100_000) for lang in languages}\n",
    "# Loads a csv for each language that contains x \n",
    "# datapoints of audio recording, if unspecified\n",
    "# then no datapoints\n",
    "\n",
    "lang_people = {lang : person_to_group(df) for lang, df in files.items()}\n",
    "# Inside each dataframe makes a dictionary mapping\n",
    "# Each unique speaker to all the audio files\n",
    "# They have produces\n",
    "\n",
    "for lang, groups in lang_people.items():\n",
    "    print(f'Unique {lang} speakers: {len(groups)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dcdec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: de complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/om2/user/jwdase/miniconda3/envs/torchenv/lib/python3.10/site-packages/mutagen/_util.py:251\u001b[0m, in \u001b[0;36m_openfile\u001b[0;34m(instance, filething, filename, fileobj, writable, create)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwritable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/om2/user/moshepol/prosody/data/raw_audio/en/clips/common_voice_en_27321449.mp3'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m lang_people_to_paths \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang, lang_dict \u001b[38;5;129;01min\u001b[39;00m lang_people\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     lang_people_to_paths[lang] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 11\u001b[0m         {people : random\u001b[38;5;241m.\u001b[39msample(x \u001b[38;5;241m:=\u001b[39m valid_paths(df, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, lang), \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x), choices)) \u001b[38;5;28;01mfor\u001b[39;00m people, df \u001b[38;5;129;01min\u001b[39;00m lang_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m lang_people_to_paths \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang, lang_dict \u001b[38;5;129;01min\u001b[39;00m lang_people\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     lang_people_to_paths[lang] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 11\u001b[0m         {people : random\u001b[38;5;241m.\u001b[39msample(x \u001b[38;5;241m:=\u001b[39m \u001b[43mvalid_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x), choices)) \u001b[38;5;28;01mfor\u001b[39;00m people, df \u001b[38;5;129;01min\u001b[39;00m lang_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/rdma/vast-rdma/vast-home/jwdase/projects/language-detection/src/langaugedetection/data/audio_length.py:65\u001b[0m, in \u001b[0;36mvalid_paths\u001b[0;34m(df, length, delta, language)\u001b[0m\n\u001b[1;32m     62\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[0;32m---> 65\u001b[0m     file_len \u001b[38;5;241m=\u001b[39m \u001b[43mget_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/rdma/vast-rdma/vast-home/jwdase/projects/language-detection/src/langaugedetection/data/audio_length.py:12\u001b[0m, in \u001b[0;36mget_length\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mAttemps to get length of audio\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mif path is not there, ignores\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MutagenError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Signal path is not valid\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/jwdase/miniconda3/envs/torchenv/lib/python3.10/site-packages/mutagen/_util.py:162\u001b[0m, in \u001b[0;36mloadfile.<locals>.wrap.<locals>.wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    160\u001b[0m     filething, filename, fileobj, args, kwargs \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    161\u001b[0m         convert_file_args(args, kwargs)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _openfile(\u001b[38;5;28;01mNone\u001b[39;00m, filething, filename, fileobj,\n\u001b[1;32m    163\u001b[0m                    writable, create) \u001b[38;5;28;01mas\u001b[39;00m h:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(h, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/om2/user/jwdase/miniconda3/envs/torchenv/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/jwdase/miniconda3/envs/torchenv/lib/python3.10/site-packages/mutagen/_util.py:251\u001b[0m, in \u001b[0;36m_openfile\u001b[0;34m(instance, filething, filename, fileobj, writable, create)\u001b[0m\n\u001b[1;32m    249\u001b[0m inmemory_fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwritable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m writable \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEOPNOTSUPP:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;66;03m# Some file systems (gvfs over fuse) don't support opening\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# files read/write. To make things still work read the whole\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;66;03m# file into an in-memory file like object and write it back\u001b[39;00m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;66;03m# later.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;66;03m# https://github.com/quodlibet/mutagen/issues/300\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langaugedetection.data.audio_length import valid_paths, random_audio\n",
    "import random\n",
    "\n",
    "choices = 2\n",
    "\n",
    "lang_people_to_paths = {}\n",
    "\n",
    "# Speedup --> Run once and save to .csv\n",
    "# Maybe cap by maximum number of speaker\n",
    "# \n",
    "\n",
    "for lang, lang_dict in lang_people.items():\n",
    "\n",
    "    lang_people_to_paths[lang] = (\n",
    "        {people : random.sample(x := valid_paths(df, 5, 1, lang), min(len(x), choices)) for people, df in lang_dict.items()}\n",
    "    )\n",
    "\n",
    "    print(f'Language: {lang} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1494118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: de with 11073 speakers\n",
      "Language: en with 28449 speakers\n",
      "Language: es with 12099 speakers\n",
      "Language: it with 6157 speakers\n"
     ]
    }
   ],
   "source": [
    "for lang, df in lang_people_to_paths.items():\n",
    "    print(f'Language: {lang} with {len(df)} speakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooses_speaker(d, fraction = .8):\n",
    "    '''\n",
    "    Splits the dataset to be 80% of training\n",
    "    '''\n",
    "    train_keys = set(random.sample(list(d.keys()), int(.8 * len(d.keys()))))\n",
    "    test_keys = set(d.keys()) - train_keys\n",
    "\n",
    "    return [d[key] for key in train_keys], [d[key] for key in test_keys]\n",
    "\n",
    "\n",
    "lang_train = {}\n",
    "lang_test = {}\n",
    "\n",
    "def flatten(array):\n",
    "    '''\n",
    "    Takes in an array within an array and flattens in\n",
    "    '''\n",
    "    x = []\n",
    "    for x_val in array:\n",
    "        if isinstance(x, list):\n",
    "            for x__val in x_val:\n",
    "                x.append(x__val)\n",
    "        else:\n",
    "            x.append(x_val)\n",
    "\n",
    "    return x\n",
    "\n",
    "for lang, dictionary in lang_people_to_paths.items():\n",
    "    train, test = chooses_speaker(dictionary)\n",
    "\n",
    "    lang_train[lang] = flatten(train)\n",
    "    lang_test[lang] = flatten(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ef40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: de, Training: 3762, Testing: 938\n",
      "Language: en, Training: 2341, Testing: 641\n",
      "Language: es, Training: 4488, Testing: 1073\n",
      "Language: it, Training: 3157, Testing: 860\n"
     ]
    }
   ],
   "source": [
    "min_train = 1_000_000\n",
    "min_test = 1_000_000\n",
    "\n",
    "for (lang, train_item), (lang, test_item) in zip(lang_train.items(), lang_test.items()):\n",
    "    print(f'Language: {lang}, Training: {len(train_item)}, Testing: {len(test_item)}')\n",
    "\n",
    "    min_train = min(min_train, len(train_item))\n",
    "    min_test = min(min_test, len(test_item))\n",
    "\n",
    "print(f'Training Size will be: {min_train}')\n",
    "print(f'Testing Size will be: {min_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31091b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten to shortest\n",
    "train_choices = int((min_train // 100) * 100)\n",
    "test_choices = int((min_test // 100) * 100)\n",
    "\n",
    "lang_short_train = {}\n",
    "lang_short_test = {}\n",
    "\n",
    "for (lang, train_item), (lang, test_item) in zip(lang_train.items(), lang_test.items()):\n",
    "    lang_short_train[lang] = random.sample(train_item, train_choices)\n",
    "    lang_short_test[lang] = random.sample(test_item, test_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1241fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: de, Training: 2200, Testing: 600\n",
      "Language: en, Training: 2200, Testing: 600\n",
      "Language: es, Training: 2200, Testing: 600\n",
      "Language: it, Training: 2200, Testing: 600\n"
     ]
    }
   ],
   "source": [
    "for (lang, train_item), (lang, test_item) in zip(lang_short_train.items(), lang_short_test.items()):\n",
    "    print(f'Language: {lang}, Training: {len(train_item)}, Testing: {len(test_item)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198db4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langaugedetection.data.spectrogram import parse\n",
    "from langaugedetection.data.tensor_construct import build_tensor\n",
    "\n",
    "train_tensor = {}\n",
    "test_tensor = {}\n",
    "\n",
    "for (lang, train_item), (lang, test_item) in zip(lang_short_train.items(), lang_short_test.items()):\n",
    "    train_tensor[lang] = build_tensor(parse(train_item))\n",
    "    test_tensor[lang] = build_tensor(parse(test_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3513382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de tensor shape is: torch.Size([2200, 1, 1025, 216])\n",
      "en tensor shape is: torch.Size([2200, 1, 1025, 216])\n",
      "es tensor shape is: torch.Size([2200, 1, 1025, 216])\n",
      "it tensor shape is: torch.Size([2200, 1, 1025, 216])\n"
     ]
    }
   ],
   "source": [
    "for lang, train in train_tensor.items():\n",
    "    print(f'{lang} tensor shape is: {train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['de' 'en' 'es' 'it']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(list(train_tensor.keys()))\n",
    "\n",
    "train_label_array = {lang : encoder.transform([lang] * train.shape[0]) for lang, train in train_tensor.items()}\n",
    "test_label_array = {lang : encoder.transform([lang] * test.shape[0]) for lang, test in test_tensor.items()}\n",
    "\n",
    "print(f'Classes: {encoder.classes_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce3864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training values: 8800\n",
      "Testing values: 2400\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "from langaugedetection.data.tensor_construct import split_dataset\n",
    "\n",
    "train_datasets = []\n",
    "for (lang, train), (lang, label) in zip(train_tensor.items(), train_label_array.items()):\n",
    "    train_datasets.append(TensorDataset(train, torch.tensor(label, dtype = torch.long)))\n",
    "\n",
    "\n",
    "test_datasets = []\n",
    "for (lang, test), (lang, label) in zip(test_tensor.items(), test_label_array.items()):\n",
    "    test_datasets.append(TensorDataset(test, torch.tensor(label, dtype = torch.long)))\n",
    "\n",
    "\n",
    "train = ConcatDataset(train_datasets)\n",
    "test = ConcatDataset(test_datasets)\n",
    "\n",
    "print(f'Training values: {len(train)}')\n",
    "print(f'Testing values: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train, batch_size=64, shuffle = True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LanguageDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 2 Convolution Layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Neuron Layers\n",
    "        # Now apply linear layer --> Dimensions of input are \n",
    "        # Con1 \n",
    "        # (1025, 216) --> (512, 108)\n",
    "        # Con2\n",
    "        # (512, 108) --> (256, 54)\n",
    "        # Now we have 32 of these with respective filters applied\n",
    "        self.fc1 = nn.Linear(32 * 256 * 54, 256)\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "        self.fc3 = nn.Linear(32, len(languages))\n",
    "\n",
    "        # Relu, Pool Function\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 2D Convolution Apllication\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten Dimensions\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Dense Layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = LanguageDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68657fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b903e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1 /2], loss 1.436499834060669\n",
      "Epoch : [2 /2], loss 1.3583611249923706\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.train()\n",
    "num_epochs = 16 # Should be around 25\n",
    "total_loss = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x_batch, y_batch in loader:\n",
    "\n",
    "        # Evaluate\n",
    "        outputs = model(x_batch).squeeze(1)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Update Model\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    total_loss.append(epoch_loss / len(loader))\n",
    "\n",
    "    print(f'Epoch : [{i+1} /{num_epochs}], loss {total_loss[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ab93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output, Training Loss\n",
    "with open('models/model2.txt', 'w') as f:\n",
    "    for i, loss in enumerate(total_loss):\n",
    "        f.write(f'Epoch {i}: {loss:.4f} loss\\n')\n",
    "\n",
    "# Save output, Testing Tensor\n",
    "torch.save(test, 'models/test2.pt')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/model2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
